---
title: 센서 퓨전(Sensor Fusion)
created: 2025-01-24 12:53
alias:
tags:
---
여러 종류의 센서 데이터를 조합하여 **더 정확하고 신뢰성 있는 환경 인식 및 상태 추정을 수행하는 기술**입니다.  
각 센서는 서로 다른 특성과 한계를 가지므로, 여러 센서를 함께 사용하면 개별 센서의 약점을 보완하고, **정확도와 강건성을 향상**할 수 있습니다.

---

### 퓨전의 필요성

로봇이나 자율주행차가 이동할 때, **단일 센서만 사용하면 다양한 문제에 직면할 수 있습니다.** 예를 들어:

- **LiDAR의 한계:**
    
    - 유리, 물과 같은 투명한 재질에 대한 인식 어려움
    - 조밀한 환경에서 반사 노이즈 발생
    - 가격이 비싸고 무게가 무거움
- **RGB-D 카메라의 한계:**
    
    - 조명 변화에 취약(어두운 곳에서 성능 저하)
    - 색상이 비슷한 환경에서 깊이 데이터 오류 발생
- **IMU의 한계:**
    
    - 시간에 따라 누적 오차(드리프트) 증가
    - 충격, 진동에 민감

**해결책:**  
각 센서의 장점을 결합하여 서로의 단점을 보완하는 것이 **센서 퓨전**입니다.

---

###### 센서 퓨전의 적용 예시 (LiDAR + 카메라 + IMU 조합)
![[journals/temp/센서 퓨전의 적용 예시 (LiDAR + 카메라 + IMU 조합)]]


---

###### 센서 퓨전 알고리즘
![[journals/temp/센서 퓨전 알고리즘]]


---

### 센서 퓨전의 이점

1. **정확도 향상:**
    
    - 개별 센서보다 높은 신뢰성 제공
    - 지형, 조명 변화, 환경 변화에 대한 강건성 증가
2. **실시간 대응 가능:**
    
    - IMU의 빠른 반응 속도와 LiDAR의 공간 측정 결합으로 지연 최소화
3. **에너지 효율 최적화:**
    
    - 일부 센서만 활성화하는 방식으로 전력 소비 절감 가능

---

### 센서 퓨전 구현 방법

1. **하드웨어 선택:**
    
    - 고성능 IMU (예: MPU6050, BNO055)
    - 3D LiDAR (예: RPLiDAR, Velodyne)
    - RGB-D 카메라 (예: Intel RealSense, Kinect)
2. **소프트웨어 스택 구성:**
    
    - **ROS (Robot Operating System):** 센서 간 통합 및 처리
    - **PCL(Point Cloud Library):** LiDAR 데이터 시각화
    - **OpenCV:** 카메라 영상 처리
    - **Edge AI (NVIDIA Jetson, Raspberry Pi):** 실시간 데이터 처리

---

### 센서 퓨전의 적용 사례

1. **자율 주행 RC카:**
    
    - LiDAR + IMU + 카메라 조합으로 장애물 탐지 및 회피
    - ROS를 활용한 실시간 SLAM 적용
2. **산업용 점검 로봇:**
    
    - 덕트 내부 환경 인식을 위해 LiDAR + Depth 카메라 사용
    - Wi-Fi 기반 원격 모니터링
3. **드론 자율 비행:**
    
    - IMU + 카메라를 이용해 실내 GPS 없는 환경에서 안정적인 비행 수행

---

### **결론 및 요약**

- 센서 퓨전은 **LiDAR, RGB-D 카메라, IMU**와 같은 여러 센서 데이터를 조합하여 **정확한 환경 인식 및 자율 주행 성능 향상**을 목표로 합니다.
- 다양한 퓨전 알고리즘(칼만 필터, 보완 필터)을 사용해 각 센서의 장단점을 보완.
- 이를 통해 로봇이 덕트 내부 탐사 등에서 정밀한 작업을 수행할 수 있도록 도움.


