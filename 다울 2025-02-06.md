---
title: 다울 2025-02-06
created: 2025-02-06 07:58
aliases: 
tags: [다울일간노트]
---
- [x] 나스 솔루션 link, source 백업하기 ✅ 2025-02-06

Yesterday: [[다울 2025-02-05]] 
Tomorrow: [[다울 2025-02-07]] 




## 오늘 작업 목표




## Not done yet

```dataviewjs

dv.taskList(dv.pages('-"3. Resource/Templates"').file.tasks

.where(t => !t.completed && !t.text.includes("@frank") &&

!t.text.includes("#task")

))

```

---

## 배운 것




## 정리가 필요한 메모는 아래에


**카메라 투영 행렬(camera projection matrix)** 을 나타내며, 
3D 세계 좌표계를 2D 이미지 평면으로 변환하는 과정입니다. 
이를 통해 3D 공간상의 한 점을 카메라 이미지에서의 픽셀 좌표로 변환



이 수식은 **카메라 투영 행렬(camera projection matrix)**을 나타내며, 3D 세계 좌표계를 2D 이미지 평면으로 변환하는 과정입니다. 이를 통해 3D 공간상의 한 점을 카메라 이미지에서의 픽셀 좌표로 변환할 수 있습니다.

---

### **수식의 의미**

수식은 다음과 같이 표현됩니다.
![[../noGitSync/Attachments/Pasted image 20250206081247.png]]


이를 단순화하면,
![[../noGitSync/Attachments/Pasted image 20250206081404.png]]


#### **구성 요소**

1. **세계 좌표계 (World Coordinates)**
![[../noGitSync/Attachments/Pasted image 20250206081426.png]]
    : 3D 공간상의 한 점의 동차 좌표(Homogeneous Coordinates).
1. **카메라 외부 행렬 (Extrinsic Matrix)**
    ![[../noGitSync/Attachments/Pasted image 20250206081438.png]]
    - : 3x4 크기의 행렬로, 3D 점을 카메라 좌표계로 변환하는 역할.
        - R : 3×3 회전 행렬(Rotation Matrix), 카메라의 방향을 정의.
        - t : 3×1 이동 벡터(Translation Vector), 카메라 위치를 정의.
2. **카메라 내부 행렬 (Intrinsic Matrix)**
    
    - A : 3×3 카메라 내부 파라미터 행렬. 
      ![[../noGitSync/Attachments/Pasted image 20250206081504.png]]
    - 
      ![[../noGitSync/Attachments/Pasted image 20250206081527.png]]
        - 
        - $f_x, f_y$ : 초점 거리(Focal Length), 픽셀 단위.
        - $c_x, c_y$ : 이미지 중심 좌표(Principal Point).
        - **skew** : 카메라의 축 왜곡(Skew Parameter), 일반적으로 0.
3. **2D 이미지 좌표 (Image Coordinates)**
    ![[../noGitSync/Attachments/Pasted image 20250206081648.png]]
    -  : 이미지 평면에서 대응되는 픽셀 좌표.
    - s : 깊이(depth)와 관련된 스케일 팩터.

---

### **설명 및 활용**

- 이 식은 **카메라 캘리브레이션 및 3D 재구성(Structure from Motion, SLAM, AR 등)**에서 핵심적으로 사용됨.
- **SLAM(Simultaneous Localization and Mapping)**에서 3D 포인트를 카메라 프레임으로 변환할 때 활용.
- **LiDAR & 카메라 캘리브레이션**에서도 중요한 변환 행렬.

---

### **요약**

- **3D 좌표 → 2D 이미지 좌표** 변환을 수행하는 공식.
- 카메라의 **내부(intrinsic) 및 외부(extrinsic) 파라미터**를 사용하여 변환.
- **SLAM, AR, 컴퓨터 비전, 로봇공학**에서 필수적으로 사용됨.

이 개념이 SLAM 및 3D 매핑에서 어떻게 적용되는지 추가 설명이 필요하면 알려주세요! 🚀


![[../noGitSync/Attachments/Pasted image 20250206084038.png]]
참조 : https://gnaseel.tistory.com/44

World frame과 Camera frame은 같은 단위계에서 중심만 바뀔 뿐이므로 라이다와 카메라의 실제 물리적 거리만 반영해주면 된다.


R은 보통 3 * 3 행렬로 표현되는 회전변환 행렬이고, t는 3 * 1벡터로 표현되는 벡터
(Xc, Yc, Zc) = (R, t) * (Xw, Yw,  Zw)
카메라 좌표계 = (extrinsic parameter , 월드 좌표계)

원근법을 반영하기 위해 Camera frame의 데이터를 pixel frame으로 옮겨야 한다.

pixel frame은 카메라 초점으로부터 거리가 1인 가상의 평면을 뜻한다.

원근법 해결은 생각보다 간단한데, Camera frame의 X와 Y값을 Z값으로 나눠주면 된다.

멀리있으면 작아지고, 가까이있으면 커진다.

첫 번째 문제였던 단위 변환을 해결해야하는데,  이것을 해결해주는 것이 intrinsic parameter  f와 c이다.

초점거리를 나타내는 f는 카메라 렌즈와 이미지센서 사이의 간격이 이미지의 셀보다 몇 배 큰지 나타내주는데,

일반적으로 현대 카메라는 fx와 fy가 같다

Calibration을 간단하게 설명하자면 서로의 좌표계를 맞추는 행위
![[../noGitSync/Attachments/Pasted image 20250206084328.png]]

# ORB-SLAM3 
https://www.youtube.com/watch?v=UVb3AFgabu8

루프 클로저 설명

loop detection -> loop fusion -> optimization 단계



•- 센서 보정  
  
- ORB‑SLAM3의 카메라 기반 Visual SLAM에 LiDAR의 정밀한 거리 정보를 추가  
- ORB‑SLAM3 연산으로 카메라의 자세와 위치 추정 및 맵 포인트 보정  
이후 LiDAR 스캔을 별도로 지도에 누적하여 포인트 클라우드 형태로 정합(I­CP, scan matching 등)  
각각 수집한 후에 두 결과를 후처리 단계에서 병합하여 보정 (Loosely-coupled 방식)  
후처리는 Noise 제거, 필터링을 통해 PCD 정제  
로봇의 위치와 주변 환경의 맵을 업데이트  
생성된 맵을 바탕으로 자율주행 경로 계획을 수행  
새로운 영역을 탐색하면서 이 과정을 반복  
전체 환경의 3D 맵을 점진적으로 완성