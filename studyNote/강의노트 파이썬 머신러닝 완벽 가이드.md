---
title: 강의노트 파이썬 머신러닝 완벽 가이드
created: 2025-07-24 10:48
alias:
tags:
---
## 섹션 1. 강의 소개

## 섹션 2. 머신러닝 개념
### 머신러닝 필요성 
특징들을 if else 조건으로 구분하기 어렵다. 너무 많이 필요.

일반적인 알고리즘은 
input a, b
규칙을 잘 만들어서
output c를 얻기.

머신러닝은
input a, b
output c 
여러 세트를 주고 규칙을 컴퓨터가 만들도록

for 복잡한 문제 해결
데이터의 패턴 학습. 예측 수행
예측 분석 => 새로운 의미와 인사이트 발굴 => 이익 실현


### 머신러닝 유형
분류 기준 답 유무
feature 기반
문제 답
#### 지도학습
종류
- 분류
- 회귀
- 추천 시스템
- 시각/음성 감지/인지


#### 비지도학습
종류
- 군집화(클러스터링)
- 차원축소
- 토픽 모델링, 문서 군집화

![[../../noGitSync/Attachments/Pasted image 20250724114445.png]]

### 머신러닝 단점
데이터 의존적 각비지 인 가비지 아웃
학습 데이터에 과적합, 실제 문제 해결에 적용 어렵
머신러닝 블랙박스. 

**데이터만 집어넣으면 자동으로 최적화된 결과를 도출할 것이라는 환상**
직접 개발자가 만든 코드보다 정확도가 떨어질 수도

좋은 데이터 필요.
데이터의 특성, 최적 알고리즘, 파라미터 구성 능력 요구

구글 페이스북의 데이터로 최적화된 머신러닝 모델을 다른 회사가 이길 수 있나

머신러닝 모델을 가지고 있느냐에 따라 기업의 경쟁력이 좌우될 것

### 파이썬 기반 머신러닝 장점, 구성요소
#### R과 파이썬 비교
##### R 장점
통계 분석에 능함.

##### 파이썬 장점
개발언어
직관적 문법
객체지향, 함수형 모두 포괄
다양한 라이브러리

인터프리터 언어 특성상 느리지만 쉽고 유연함.

데스크탑, 서버, 네트어크, 시스템, iot 등 다양한 영역에서 사용되고 있음.

머신러닝 서비스를 만들면
서비스 모듈로 만들기 좋음.

### 파이썬 머신러닝을 위한 s/w 설치
아나콘다 설치. 
기존 base환경의 라이브러리가 너무 많음. 시간 오래걸림
아나콘다 지우고 새로 설치하자.

파이썬 3.9 버전
가상환경을 새로 만들자. 

libmamba 설치하고
```

```


```
conda create -n ml_env -c conda-forge --solver=libmamba python=3.9 scikit-learn=1.0.2 xgboost=1.5.0 lightgbm=3.3.2 pandas notebook
```

ml_env

```
conda activate ml_env
```

```

```

### 사이킷런 업그레이드 수행 및 XGBoost와 LightGBM 설치

#### xgboost 설치
1.5.0


visual studio installer 설치

c++을 사용한 데스크톱 개발 설치

#### LightGBM 설치
3.3.2



### 주피터 노트북 사용법과 넘파이/판다스 필요성

#### 주피터 노트북 사용법
대화형 파이썬 툴
전체 프로그램에서 특정 코드 영역별로 개별 수행 지원
영역별 코드 이해 명확

공책. 중요 코드 단위로 설명 적어.
셀 안에 코드 실행. 겨로가를 볼 수 있게. 직관적으로 해당 코드 역할 이해

주피터 노트북 실행.
콘솔의 역할.
실행 pc 로컬호스트 8888에 웹 서버 실행.
웹서버에 자동 접속

컴퓨터의 사용자 홈디렉토리로 가.
new 버튼으로 새로운 파이썬 개발 환경 커널을 만들어.



###### 주피터 노트북의 작업 효율을 극적으로 높여주는 유용한 단축키들을 모아서 정리
![[journals/temp/주피터 노트북의 작업 효율을 극적으로 높여주는 유용한 단축키들을 모아서 정리]]


ctrl + enter로 셀 실행
alt + enter로 셀 실행하고 다음 셀 생성

esc하고 명령모드 전환 후에 m 으로 마크다운 모드로 전환

esc하고 y로 코드 모드로 전환


상단바 edit > clear cell output, clear outputs of all cells

상단바 kernel > restart and clear all outputs로 다시 처음부터 실행하는 상태로 만들어.

상단바 kernel > interrupt로 무한루프같은 상황에 빠져나오기

file > duplicate로 노트의 카피 만들고

file > save로 노트북 저장


차시예고
![[attaches/Pasted image 20250728135526.png]]



numpy는 api 방대함.
document도 많이 없고

pandas는 다양한 document 있음.

numpy가 시간 많이 잡아 먹을 것.

ml을 위해 numpy, pandas에 너무 많은 시간을 들이는 건 반대.

전문적으로 공부하는 건 ml 하면서 하는게

numpy, pandas에 대한 좋은 얇은 책, 별도 강좌도 있더라.

코드 개발하면서 api 이것 저것 사용해보면서 익히는 방향으로.

ml과 numpy, pandas 함께 배우기.

### 넘파이
ndarray : n차원(dimension) 배열(array) 객체

중첩된 리스트.
1차원 배열은 그냥 배열(선)

2차원 배열은 1차원 배열(선) n개

3차원 배열은 2차원 배열(면적)이 n개

4차원 배열은 3차원 배열이 n개

![[../../noGitSync/Attachments/Pasted image 20250728142157.png]]

한 차원 밑에 있는 요소들을 원소로 가지는 형태의 배열이 ndarray다.

ndarray 사용.

List 는 대용량 데이터 처리하기 힘듬

numpy는 벡터 프로세싱이 돼서 금방 처리 가능.

![[attaches/Pasted image 20250728142925.png]]


반드시 알고 가야하는 차원 shape

ndarray 형태(Shap)와 차원

ndarray.ndim 속성으로 차원 알 수 있어도 ndarray.shape를 주로 쓴다. 
ndarray.shape.len 하면 나옴.

tuple 맨 마지막에 ,가 들어있으면 무조건 1차원.
![[../../noGitSync/Attachments/Pasted image 20250728143531.png]]


ndarray 타입

다 같은 타입이어야 한다.
int, float 같이 담으면 메모리 사이즈 큰 float으로 자동 형변환.
ndarray.dtype으로 타입 확인 가능.


![[../../noGitSync/Attachments/Pasted image 20250728143709.png]]


astype()을 이용해서 형변환
대용량 데이터를 ndarray로 만들 때 메모리 절약을 위해 주로 사용.
int를 float으로 형변환.

대용량 데이터 다룰 시 메모리 절약을 위해 특히 형변환 고려

![[attaches/Pasted image 20250728143931.png]]



### ndarray 실습

```python
import numpy as np

list1 = [1, 2, 3]
print('list1 type:', type(list1))
array1 = np.array(list1)
#array1 = np.array([1,2,3])
print('array1 type:',type(array1))
print('array1 array 형태:',array1.shape)

array2 = np.array([[1,2,3],
                  [2,3,4]])
print('array2 type:',type(array2))
print('array2 array 형태:',array2.shape)

array3 = np.array([[1,2,3]])
print('array3 type:',type(array3))
print('array3 array 형태:',array3.shape)
```

array1은 1차원 배열,
array3은 2차원 배열. 
행이 1인 2차원 배열. 이런 경우 주의 필요.

array3에서 행이 1인 것을 주의하라는 의미는 **차원(dimension)과 형태(shape)의 해석**에 대한 것입니다.

### 1차원 배열과 2차원 배열의 구분
제공된 코드를 보면 `array1`은 `[1, 2, 3]`이라는 리스트를 기반으로 생성된 
1차원 배열입니다. 
이 경우 `shape`는 `(3,)`으로 나타나죠. 
이는 요소가 3개인 1차원 배열임을 의미합니다.

`array3`은 `[[1, 2, 3]]`이라는 리스트 안에 또 다른 리스트가 있는 형태로, 
마치 엑셀 시트의 한 행처럼 보입니다. 
이때 `shape`는 `(1, 3)`으로 나타납니다. 
여기서 앞의 `1`은 **행의 개수**를, 뒤의 `3`은 **열의 개수**를 의미합니다.

### 왜 이 부분이 중요할까요?

- **연산 방식의 차이:** NumPy는 배열의 차원과 형태에 따라 연산을 다르게 적용합니다. 예를 들어, 1차원 배열 `(3,)`과 2차원 배열 `(1, 3)`은 시각적으로는 비슷해 보여도, 특정 연산에서는 전혀 다른 결과를 낳을 수 있습니다. 행렬 곱셈이나 브로드캐스팅(broadcasting) 규칙을 적용할 때 이런 차이가 특히 명확해집니다.
    
- **데이터 해석의 오류 방지:** 데이터를 처리할 때, 1차원 데이터로 생각하고 코드를 작성했는데 실제로는 2차원 배열(특히 행이 1개인)이라면 예상치 못한 에러가 발생하거나 잘못된 결과로 이어질 수 있습니다. 예를 들어, 특정 머신러닝 모델의 입력 데이터는 특정 형태를 요구하는 경우가 많습니다. 이때 `(3,)` 형태와 `(1, 3)` 형태를 혼동하면 모델이 데이터를 제대로 처리하지 못할 수 있습니다.
    
- **코드의 명확성:** `array3`처럼 행이 1개인 2차원 배열은 나중에 코드를 볼 때 개발자가 1차원 배열과 혼동하기 쉽습니다. 명확하게 2차원 배열임을 인지하고 코드를 작성해야 합니다.
    

간단히 말해, `(3,)`은 "요소가 3개인 한 줄짜리 데이터"이고, `(1, 3)`은 "행이 1개이고 열이 3개인 표 형태의 데이터"라고 이해하면 됩니다. 둘은 엄연히 다른 형태이며, NumPy를 효율적으로 사용하려면 이러한 차원을 정확히 이해하는 것이 중요합니다.


```python
list2 = [1, 2, 'test']
array2 = np.array(list2)
print(array2, array2.dtype)

list3 = [1, 2, 3.0]
array3 = np.array(list3)
print(array3, array3.dtype)
```

```결과
['1' '2' 'test'] <U21
[1. 2. 3.] float64
```

`U21`은 문자열 의미
int가 float으로 자동 형변환(메모리 큰 쪽으로)


### ndarray axis 축
numpy의 axis가 헷갈린다.
2차원배열의 axis0, axis1에 대해서

단일 원소로 표현될 수 있는 가장 작은 단위. `1, 2, 3, 4`
이게 axis1
그리고 axis1의 요소들이 뭉쳐서 여러 개가 있으면
`[1,2,3,4]`, `[5,6,7,8]`
차원이 하나씩 뒤에서부터 앞으로 감.
이게 axis0

같은 논리로 3차원 배열.
뒤에서부터 생각하자.
가장 기본이 되는 1, 2, 3, 4
이게 axis2,

axis2가 여러 개 있어. 
`[1,2,3,4]`, `[5,6,7,8]`
이게 axis1,

이런 axis1이 다수 있으면
이게 axis0


![[attaches/Pasted image 20250728150045.png]]

4차원을 생각해보자
axis3, axis2, axis1, axis0 이렇게.

2차원배열을 행렬로 말하지만 엄밀히 말하면
행이 아니라 axis0이 된다.
열은 axis1이 된다.

처음에는 헷갈릴 수 있다.

우리가 주로 다루는 차원은 1차원 or 2차원. 외워도 좋다.

3차원은 그리 많이 다루지 않음.

딥러닝을 할 때 3차원을 다루게 될 것.


### ndarray 초기화 방법. 차원 크기 변경 reshape() 이해 01

#### np.arange(10)
0~9까지 10개의 원소를 iteration할 수 있게

np.zeros((3,2), dtype='int32')
`(3,2)`는 튜플.
zeros는 원소를 전부 0으로 채워라.

np.ones((3,2))
ones는 원소를 전부 1로 채워라.
타입을 안 적어서 기본 float64로 채워짐. 

만들어야 할 데이터의 shape을 알고 값은 모를 때 일단 만들기.
로직을 써서 나중에 값이 업데이트 되도록.

![[attaches/Pasted image 20250728150638.png]]

#### reshpae()

reshape(2, 5)
2차원 2x5 ndarray로 변환.

![[attaches/Pasted image 20250728150808.png]]

reshape할 때 처음에 헷갈리는 요소
reshape(-1, 5)

인자에 -1을 부여? 
axis의 크기를 가변적으로.


10개 요소를 reshape(-1,5) 하면 
```
[[0,1,2,3,4]
[5,6,7,8]]
```
(2,5)가 됨.

8개 요소를 reshape(-1,5) 하면? 컴파일에러
```python
array1 = array1 = np.arange(10)  
array1.reshape(4,3)

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[10], line 1
----> 1 array1.reshape(4,3)

ValueError: cannot reshape array of size 10 into shape (4,3)
```
10개를 어떻게 4,3 하라는거니 라고 말한다.


```python
array1 = np.arange(10)
array4 = array1.reshape(-1,4)

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[12], line 2
      1 array1 = np.arange(10)
----> 2 array4 = array1.reshape(-1,4)

ValueError: cannot reshape array of size 10 into shape (4)
```


![[attaches/Pasted image 20250728151134.png]]


#### reshape(-1,1), reshape(-1,)은 다르다

reshape(5, )은 1d

array1d = `[0,1,2,3,4]`일 때
reshape(-1,1)은 2차원. shape는 (5,1)
```
[[0]
[1]
[2]
[3]
[4]]
```

array2d = `[0] [1] [2] [3] [4]`일 때
reshape(-1,)는 무조건 1d로 변환.
shape는 (5, ) `[0, 1, 2, 3, 4]`

머신러닝 API가 인자로 1차원 ndarray를 명확하게 2차원 ndarray로 변환하여 입력하기를 원하거나, 
반대의 경우가 있을 수 있음.

![[attaches/Pasted image 20250728151654.png]]


### numpy indexing 이해. 단일값과 슬라이싱 인덱싱

#### 유형
단일값 가져오기
여러 개의 값 가져오기

slicing
`0:9`
0부터 9개 가져오기.

fancy indexing
`[0, 1, 2]`
위치 인덱스 기반 0, 1, 2 위치에 있는 값 가져오기.

boolean indexing
굉장히 유용
조건을 인덱싱에 걸어.
조건에 맞는 위치 인덱스의 값을 찾아.
true, false값

![[attaches/Pasted image 20250728160335.png]]


#### 단일 값 추출 1d

원본 데이터가 있어.

ndarray 뒤에 `[]`(브레킷)이 들어가.
위치 인덱싱을 하겠다.
array1 = `[1,2,3,4,5,6,7,8,9]`
9개 요소가 있어.
index가 0~8까지

```python
array1[-1]
array1[-2]
```
-1은 맨 뒤.
-2는 맨 뒤에서 2번째.

![[attaches/Pasted image 20250728160628.png]]


```python
# 1에서 부터 9 까지의 1차원 ndarray 생성 
array1 = np.arange(start=1, stop=10)
print('array1:',array1)
# index는 0 부터 시작하므로 array1[2]는 3번째 index 위치의 데이터 값을 의미
value = array1[2]
print('value:',value)
print(type(value))

-------------------
array1: [1 2 3 4 5 6 7 8 9]
value: 3
<class 'numpy.int64'>

```

단일 인덱싱 특징. value를 추출할 때 차원에 -1


```python
print('맨 뒤의 값:',array1[-1], ', 맨 뒤에서 두번째 값:',array1[-2])

---------
맨 뒤의 값: 9 , 맨 뒤에서 두번째 값: 8

```

맨 뒤 인덱스 -1을 자주 사용함. 
맨 앞은 무조건 0, 맨 뒤는 원소 count에 따라 달라져.
그래서 -1로 쉽게 가져온다.

#### 단일 값 추출 2d
axis1은 열
axis0은 행
```python
array2d[0,0] = 1
array2d[0,1] = 2
array2d[1,0] = 4
array2d[2,2] = 9
```

![[attaches/Pasted image 20250728160747.png]]


```python
    array1d = np.arange(start=1, stop=10)
    array2d = array1d.reshape(3,3)
    print(array2d)
    print('(row=0,col=0) index 가리키는 값:', array2d[0,0] )
    print('(row=0,col=1) index 가리키는 값:', array2d[0,1] )
    print('(row=1,col=0) index 가리키는 값:', array2d[1,0] )
    print('(row=2,col=2) index 가리키는 값:', array2d[2,2] )

---------
[[1 2 3]
 [4 5 6]
 [7 8 9]]
(row=0,col=0) index 가리키는 값: 1
(row=0,col=1) index 가리키는 값: 2
(row=1,col=0) index 가리키는 값: 4
(row=2,col=2) index 가리키는 값: 9

```


```python
[[1 2 3]
 [4 5 6]
 [7 8 9]]
(row=0,col=0) index 가리키는 값: 1
(row=0,col=1) index 가리키는 값: 2
(row=1,col=0) index 가리키는 값: 4
(row=2,col=2) index 가리키는 값: 9
array3.shape

----------
array1: [1 2 3 4 5 6 7 8 9]
array3: [1 2 3]
<class 'numpy.ndarray'>
(3,)
```

#### slicing 1d
`:`를 이용하여 연속된 값 선택.

`시작인덱스 : 종료인덱스`

![[attaches/Pasted image 20250728160851.png]]



```python
array1 = np.arange(start=1, stop=10)
# 위치 인덱스 0-2(2포함)까지 추출
array4 = array1[:3]
print(array4)

# 위치 인덱스 3부터 마지막까지 추출
array5 = array1[3:]
print(array5)

# 위치 인덱스로 전체 데이터 추출
array6 = array5[:]
print(array6)


-------------------
[1 2 3]
[4 5 6 7 8 9]
[4 5 6 7 8 9]

```

#### slicing 2d
```
array2d[:2, 0]
```
일 때 앞에는 slicing이고 뒤에는 그냥 단일 값
그래서 1d


![[attaches/Pasted image 20250728161222.png]]


```python
array1d = np.arange(start=1, stop=10)
array2d = array1d.reshape(3,3)
print('array2d:\n',array2d)

print('array2d[0:2, 0:2] \n', array2d[0:2, 0:2])
print('array2d[1:3, 0:3] \n', array2d[1:3, 0:3])
print('array2d[1:3, :] \n', array2d[1:3, :])
print('array2d[:, :] \n', array2d[:, :])
print('array2d[:2, 1:] \n', array2d[:2, 1:])
print('array2d[:2, 0] \n', array2d[:2, 0])


---------------------
array2d:
 [[1 2 3]
 [4 5 6]
 [7 8 9]]
array2d[0:2, 0:2] 
 [[1 2]
 [4 5]]
array2d[1:3, 0:3] 
 [[4 5 6]
 [7 8 9]]
array2d[1:3, :] 
 [[4 5 6]
 [7 8 9]]
array2d[:, :] 
 [[1 2 3]
 [4 5 6]
 [7 8 9]]
array2d[:2, 1:] 
 [[2 3]
 [5 6]]
array2d[:2, 0] 
 [1 4]

```

`array2d[:2, 0] == [1 4]`
마지막에 단일 인덱싱 결과 차원 -1 됨.
다른 값은 2차원에 대해 슬라이싱을 해서 2차원 나옴
2차원에 대해 단일 인덱싱을 했더니 1차원 나옴

```python
print(array2d[0])
print(array2d[1])
print('array2d[0] shape:', array2d[0].shape, 'array2d[1] shape:', array2d[1].shape )


----------------------
[1 2 3]
[4 5 6]
array2d[0] shape: (3,) array2d[1] shape: (3,)

```



#### 팬시 인덱싱 1d
slicing과 유사.
여러 값 추출 can
단 slicing은 **연속된 값**만 가능.
팬시는 **불연속 값** can

```python
array[[2,4,7]]
```

ndarray 뒤에 `[]`브라킷이 나오면 인덱싱 하겠다.
브라킷 안에 ndarray가 나오거나 list가 나오거나.

2, 4, 7의 위치 인덱스를 가지는 값을 추출하라.

![[attaches/Pasted image 20250728161554.png]]





#### 팬시 인덱싱 2d

![[attaches/Pasted image 20250728161703.png]]

```python
array2d[[0,1]] == array2d[[0,1], :]
```
둘이 같다.


```python
array1d = np.arange(start=1, stop=10)
array2d = array1d.reshape(3,3)
print(array2d)

array3 = array2d[[0,1], 2]
print('array2d[[0,1], 2] => ',array3.tolist())

array4 = array2d[[0,1], 0:2]
print('array2d[[0,1], 0:2] => ',array4.tolist())

array5 = array2d[[0,1]]
print('array2d[[0,1]] => ',array5.tolist())



------------------------
[[1 2 3]
 [4 5 6]
 [7 8 9]]
array2d[[0,1], 2] =>  [3, 6]
array2d[[0,1], 0:2] =>  [[1, 2], [4, 5]]
array2d[[0,1]] =>  [[1, 2, 3], [4, 5, 6]]

```



#### 불린 인덱싱
유용
내부적으로는 동일한 방식으로 가져오지만
사용할 때 달라.

이해를 돕기 위한 sudo code
```python
array1d = np.arange(start=1, stop=10)
target = []

for i in range(0, 9):
	if array1d[i] > 5:
		target.append(array1d[i])

array_selected = np.array(target)
-------------
[6 7 8 9]

```

불린 인덱싱 사용 code
```python
array1d = np.aranged(start=0, stop=10)
print(array1d)
array1d[array1d > 5]
print('array1d > 5 불린 인덱싱 결과 값 :', array3)

-------------
[1 2 3 4 5 6 7 8 9]
array1d > 5 불린 인덱싱 결과 값 : [6 7 8 9]

```

브래킷 안에 바로 조건식을 집어넣음.
실제 코드 작성에 가장 많이 사용하게 될 것.




![[attaches/Pasted image 20250728162253.png]]


조건만 실행했을 때 결과
```python
array1d > 5

------------------
array([False, False, False, False, False,  True,  True,  True,  True])

```

조건식의 결과를 boolean 형태로 반환

```python
val = array1d > 5
print(val, type(val), val.shape)

-------------------
[False False False False False  True  True  True  True] <class 'numpy.ndarray'> (9,)
```

위치 인덱스 값을 정하지 않고 bool값만 넣어도 인덱싱이 된다.



```python
boolean_indexes = np.array([False, False, False, False, False,  True,  True,  True,  True])
array3 = array1d[boolean_indexes]
print('불린 인덱스로 필터링 결과 :', array3)

------------------
불린 인덱스로 필터링 결과 : [6 7 8 9]

```

실행해보면 결과가 같음.
자동적으로 false에 해당하는 값의 위치 인덱스를 찾지 않고 true에 해당하는 값의 위치 인덱스만 찾아서 값을 결과에 담아서 반환한다.

bool값을 통해서 인덱스 값을 찾는다.
이것을 기반으로 인덱싱을 수행.


위치 5, 6, 7, 8에 해당하는 값을 팬시 인덱싱으로 가져오는 것과 동일
```python
indexes = np.array([5,6,7,8])
array4 = array1d[ indexes ]
print('일반 인덱스로 필터링 결과 :',array4)
---------------

일반 인덱스로 필터링 결과 : [6 7 8 9]
```

불린 인덱싱 정리.
조건식만 브래킷 안에 넣으면 
true인 위치 인덱스만 찾아서 값을 준다.

![[attaches/Pasted image 20250728165454.png]]



### ndarray의 sork와 argsort

배열의 정렬
sort
#### np.sort(ndarray) 
인자로 들어온 원 행렬은 그대로 유지. 원 행렬의 정렬된 행렬을 return
c#의 linq랑 비슷하네. 원본 그대로 놔두니까.

#### ndarray.sort()
원 행렬 자체를 정렬한 형태로 변환. 


```python
org_array = np.array([ 3, 1, 9, 5]) 
print('원본 배열:', org_array)
# np.sort( )로 정렬 
sort_array1 = np.sort(org_array)         
print ('np.sort( ) 호출 후 반환된 정렬 배열:', sort_array1) 
print('np.sort( ) 호출 후 원본 배열:', org_array)
# ndarray.sort( )로 정렬
sort_array2 = org_array.sort()
print('org_array.sort( ) 호출 후 반환된 배열:', sort_array2)
print('org_array.sort( ) 호출 후 원본 배열:', org_array)

-----------------
원본 배열: [3 1 9 5]
np.sort( ) 호출 후 반환된 정렬 배열: [1 3 5 9]
np.sort( ) 호출 후 원본 배열: [3 1 9 5]
org_array.sort( ) 호출 후 반환된 배열: None
org_array.sort( ) 호출 후 원본 배열: [1 3 5 9]

```


`org_array.sort()`
이거 쓸 때 주의. 다른 변수 만들어서 할당하지 마라.
어차피 반환값이 없고 원본을 정렬된 형태로 변환하기 때문에 좋지 않은 방식



기본적으로 오름차순 정렬.
내림차순 정렬은 
```
[ :: -1 ]
```


```python
sort_array1_desc = np.sort(org_array)[::-1]
print ('내림차순으로 정렬:', sort_array1_desc) 

----------
내림차순으로 정렬: [9 5 3 1]
```



#### 2차원 배열에서 sort()
axis 기반의 sort()
np.sort(A, axis=0)

![[attaches/Pasted image 20250729092845.png]]


```python
array2d = np.array([[8, 12], 
                   [7, 1 ]])

sort_array2d_axis0 = np.sort(array2d, axis=0)
print('로우 방향으로 정렬:\n', sort_array2d_axis0)

sort_array2d_axis1 = np.sort(array2d, axis=1)
print('컬럼 방향으로 정렬:\n', sort_array2d_axis1)

-------------
로우 방향으로 정렬:
 [[ 7  1]
 [ 8 12]]
컬럼 방향으로 정렬:
 [[ 8 12]
 [ 1  7]]

```




#### argsort()
argument는 인자

np.argsort()
원본 행렬 정렬 시 행렬의 원래 인덱스가 필요할 때 사용.




```python
org_array = np.array([ 3, 1, 9, 5]) 
sort_indices = np.argsort(org_array)
print(type(sort_indices))
print('행렬 정렬 시 원본 배열의 인덱스:', sort_indices)
```

```console
<class 'numpy.ndarray'>
행렬 정렬 시 원본 배열의 인덱스: [1 0 3 2]
```


반환값이 원본과 전혀 관계없어보임.


```python
org_array = np.array([ 3, 1, 9, 5]) 
sort_indices_desc = np.argsort(org_array)[::-1]
print('행렬 내림차순 정렬 시 원본 배열의 인덱스:', sort_indices_desc)
```

```console
행렬 내림차순 정렬 시 원본 배열의 인덱스: [2 3 0 1]
```



key, value 맵핑이 안 돼.
묵시적으로 맵핑을 하는 로직을 사용할 때 argsort()가 유용하게 사용된다.

주로 언제 사용하는지.
두 ndarray를 암묵적으로 맵핑해.

name_array
score_array

성적을 오름차순 정렬하고 스코어순으로 사람 이름 출력하기
이럴 때 np.argsort() 사용.
sort_indices_asc 나온 걸로 이름을 순서대로 출력함.

```python
import numpy as np

name_array = np.array(['John', 'Mike', 'Sarah', 'Kate', 'Samuel'])
score_array= np.array([78, 95, 84, 98, 88])

sort_indices_asc = np.argsort(score_array)
print('성적 오름차순 정렬 시 score_array의 인덱스:', sort_indices_asc)
print('성적 오름차순으로 name_array의 이름 출력:', name_array[sort_indices_asc])
```

```console
성적 오름차순 정렬 시 score_array의 인덱스: [0 2 4 1 3]
성적 오름차순으로 name_array의 이름 출력: ['John' 'Sarah' 'Samuel' 'Mike' 'Kate']
```

이름을 0 2 4 1 3 순으로 출력했더니 성적 오름차순으로 이름 출력한 것.



### 선형대수 연산 - 행렬 내적, 전치행렬

#### np.dot(A, B)

행렬내적

![[attaches/Pasted image 20250729101616.png]]

```python
A = np.array([[1, 2, 3],
              [4, 5, 6]])
B = np.array([[7, 8],
              [9, 10],
              [11, 12]])

dot_product = np.dot(A, B)
print('행렬 내적 결과:\n', dot_product)
```

```console
행렬 내적 결과:
 [[ 58  64]
 [139 154]]
```



#### np.transpose(A)

전치행렬

위치를 바꿔.

transpose -> T

행 렬 위치 인덱스를 바꿔.

정방행렬일 때


행과 열이 pivoting 되는 효과가 있다.

shape(2, 2)는 그대로 2,2

shape(3,2)는 shape(2,3)

![[attaches/Pasted image 20250729101809.png]]


```python
A = np.array([[1, 2],
              [3, 4]])
transpose_mat = np.transpose(A)
print('A의 전치 행렬:\n', transpose_mat)
```

```console
A의 전치 행렬:
 [[1 3]
 [2 4]]
```


### numpy 최종정리

파이썬 머신러닝 구성하는 핵심 기반
반드시 이해 필요.
그러나 범위가 넒음
핵심 개념 위주로 숙지하는 것이 좋다.

넘파이는 선형대수 기반. 선형대수 연산을 함수로 쉽게 구현한 것

데이터 처리 목적으로 친절하지 않음.

2차원 데이터라면 데이터 가공을 위해 넘파이보다 판다스를 이용하는 것이 효율적이다.


### 판다스
#### 판다스 소개
파이썬에서 데이터 처리 인기 라이브러리
데이터 세트 대부분 2차원 데이터
행x열

인간이 이해하기 쉬운 구조. 

데이터 분석을 위한 파이썬 책도 씀.

![[attaches/Pasted image 20250729103334.png]]

금융회사 출신
프로그래머도 아닌데
너무 잘 만들어서 생태계에서 광범위하게 사용함.

금융데이터 특성상 시계열성 데이터가 많아.
api 하나만 불러서 시계열성 데이터,
집계성
시각화와 효율적인 연계

성능도 빨라.
numpy에 기반함

#### 판다스 주요 구성요소

![[attaches/Pasted image 20250729103433.png]]

##### DataFrame

colum x row 로 구성된 2차원 데이터셋

##### Series
1개 column 값으로만 구성된 1차원

둘의 차이점.
Shape(3, ) 이면 series
Shape(3, 1) 이면 dataframe

##### Index
dataframe/series의 고유한 key값 객체 
dbms의 pk에 해당

#### 기본 API
##### read_csv()

read_csv()를 이용하여 csv파일을 편리하게 DataFrame으로 로딩합니다.
read_csv()의 sep인자를 콤마(,)가 아닌 다른 분리자로 변경하여 다른 유형의 파일도 로드가 가능합니다.

```python
titanic_df = pd.read_csv('titanic_train.csv')
print('titanic 변수 type:',type(titanic_df))
```

```console
titanic 변수 type: <class 'pandas.core.frame.DataFrame'>
```

read_csv("file_name", "")
##### head()

**head()와 tail()**
head()는 DataFrame의 맨 앞부터 일부 데이터만 추출합니다. 
tail()은 DataFrame의 맨 뒤부터 일부 데이터만 추출합니다.

arg 안 넣으면 5개만, 넣으면 count 만큼 가져옴.

print() 하면 불명확하게 출력됨
```python
print(titanic_df.head())
```

그냥 `titanic_df` 를 두고 실행하면 
주피터노트북에서만 테이블을 보여줌.

주피터노트북에서 제대로 테이블을 출력하는 방법은 `display()`

```python
display(titanic_df.tail(3))
display(titanic_df.head(3))
```

###### DataFrame 출력 시 Option

![[attaches/Pasted image 20250729110518.png]]

display()를 쓰는 것이 정석이다.

##### set_option()

```python
pd.set_option('display.max_rows', 1000)
pd.set_option('display.max_colwidth', 100)
pd.set_option('display.max_columns', 100)

titanic_df
```

설정을 안 하고 display 하면 10개 기본 값. 
이렇게 값을 넣어주고 display하면 전체 테이블이 다 나옴.

##### shape()
DataFrame의 행(Row)와 열(Column) 크기를 가지고 있는 속성입니다.

```python
print('DataFrame 크기: ', titanic_df.shape)
```

```console
DataFrame 크기:  (891, 12)
```

##### describe()
##### value_counts()
##### sort_values()



dataframe 로딩



#### DataFrame의 생성

```python
dic1 = {'Name': ['Chulmin', 'Eunkyung','Jinwoong','Soobeom'],
        'Year': [2011, 2016, 2015, 2015],
        'Gender': ['Male', 'Female', 'Male', 'Male']
       }
# 딕셔너리를 DataFrame으로 변환
data_df = pd.DataFrame(dic1)
print(data_df)
print("#"*30)

# 새로운 컬럼명을 추가
data_df = pd.DataFrame(dic1, columns=["Name", "Year", "Gender", "Age"])
print(data_df)
print("#"*30)

# 인덱스를 새로운 값으로 할당. 
data_df = pd.DataFrame(dic1, index=['one','two','three','four'])
print(data_df)
print("#"*30)
```

```console
       Name  Year  Gender
0   Chulmin  2011    Male
1  Eunkyung  2016  Female
2  Jinwoong  2015    Male
3   Soobeom  2015    Male
##############################
       Name  Year  Gender  Age
0   Chulmin  2011    Male  NaN
1  Eunkyung  2016  Female  NaN
2  Jinwoong  2015    Male  NaN
3   Soobeom  2015    Male  NaN
##############################
           Name  Year  Gender
one     Chulmin  2011    Male
two    Eunkyung  2016  Female
three  Jinwoong  2015    Male
four    Soobeom  2015    Male
##############################
```

`NaN`은 not a number
`null`처럼 생각해도 무방하다.


#### DataFrame의 컬럼명과 인덱스

```python
print("columns:",titanic_df.columns)
print("index:",titanic_df.index)
print("index value:", titanic_df.index.values)
```

```console
columns: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],
      dtype='object')
index: RangeIndex(start=0, stop=891, step=1)
index value: [  0   1   2   ...  888 889 890] # 생략됨
```


#### info()
DataFrame내의 컬럼명, 데이터 타입, Null건수, 
데이터 건수 정보를 제공합니다.

```python
titanic_df.info()
```

```console
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
```


#### describe()
데이터값들의 평균,표준편차,4분위 분포도를 제공합니다. 
숫자형 컬럼들에 대해서 해당 정보를 제공합니다.

```python
titanic_df.describe()
```

![[attaches/Pasted image 20250729112958.png]]


count null값 빼고 몇 개
mean 평균
std 표준편차
min 최소

데이터의 분포도 
25% 
50%
75%
max 최대



### 판다스 value_counts 메서드

동일한 개별 데이터 값 몇 건 있는지 정보 제공
즉 개별 데이터값의 분포도를 제공합니다. 
자주 사용.

```python
value_counts = titanic_df['Pclass'].value_counts()
print(value_counts)
```

```console
Pclass
3    491
1    216
2    184
Name: count, dtype: int64
```

.head()와 비교

```python
titanic_df['Pclass'].head()
```

```console
0    3
1    1
2    3
3    1
4    3
Name: Pclass, dtype: int64
```



value_counts()는 과거에는 Series객체에서만 호출 될 수 있었지만 
현재에는 DataFram에서도 호출가능합니다.

시리즈 `value_counts()` 호출

```python
titanic_pclass = titanic_df['Pclass']
print(type(titanic_pclass))
```

```console
<class 'pandas.core.series.Series'>
```


데이터 프레임에 `value_counts()` 호출

```python
# DataFrame에서도 value_counts() 적용 가능. 
titanic_df[['Pclass', 'Embarked']].value_counts()
```

```console
Pclass  Embarked
3       S           353
2       S           164
1       S           127
        C            85
3       Q            72
        C            66
2       C            17
        Q             3
1       Q             2
Name: count, dtype: int64
```

브래킷 안에 브래킷으로 list 형태로 여러 컬럼을 넣으면 됨.
sql의 group by 연산과 비슷

정렬은 내림차순. value_count 값이 큰 값부터 정렬되기 때문에 헷갈릴 수도 있음.


value_counts() 메소드를 사용할 때는 
Null 값을 무시하고 결과값을 내놓기 쉽습니다. 
value_counts()는 Null값을 포함하여 개별 데이터 값의 건수를 계산할지 여부를 dropna 인자로 판단합니다. 
dropna는 디폴트로 True이며 이 경우는 Null값을 무시하고 개별 데이터 값의 건수를 계산합니다.

NULL값이 전체 데이터에서 비중이 클 때 dropna = true이면 데이터가 안 맞을 수 있다. 이때 dropna = false로 놓고 다시 해보면 됨.


```python
print('titanic_df 데이터 건수:', titanic_df.shape[0])
print('기본 설정인 dropna=True로 value_counts()')
# value_counts()는 디폴트로 dropna=True 이므로 value_counts(dropna=True)와 동일. 
print(titanic_df['Embarked'].value_counts())
print(titanic_df['Embarked'].value_counts(dropna=False))
```

```console
titanic_df 데이터 건수: 891
기본 설정인 dropna=True로 value_counts()
Embarked
S    644
C    168
Q     77
Name: count, dtype: int64
Embarked
S      644
C      168
Q       77
NaN      2
Name: count, dtype: int64
```




### 판다스 dataFrame 변환, 컬럼 세트 생성/수정
#### 판다스 dataFrame과 ndarray 차이점

#### dataframe과 다른 컬렉션 상호 변환
ndarray에 없는 컬럼명이 있다.
그래서 컬럼명 변환할 때 columns = `["이름", "나이"]` 이걸 넣어

list
ndarray
dict

##### dataFrame을 ndarray로 변환
`df.values` 반드시 기억

list로 변환
`df.valuess.tolist()`

dict로 변환
`df.to_dict()`


##### 1차원 dataFrame 변환

```python
import numpy as np

col_name1=['col1']
list1 = [1, 2, 3]
array1 = np.array(list1)

print('array1 shape:', array1.shape )
df_list1 = pd.DataFrame(list1, columns=col_name1)
print('1차원 리스트로 만든 DataFrame:\n', df_list1)
df_array1 = pd.DataFrame(array1, columns=col_name1)
print('1차원 ndarray로 만든 DataFrame:\n', df_array1)
```

```console
array1 shape: (3,)
1차원 리스트로 만든 DataFrame:
    col1
0     1
1     2
2     3
1차원 ndarray로 만든 DataFrame:
    col1
0     1
1     2
2     3
```

주의사항. 
`columns=` 여기 들어가는 값은 무조건 `[ ]`를 써서 넣어야 함. 단일 컬럼만 넣더라도


##### shape(2, 3)인 list와 ndarray를 dataFrame 변환
```python
# 3개의 칼럼명이 필요함. 
col_name2=['col1', 'col2', 'col3']

# 2행x3열 형태의 리스트와 ndarray 생성 한 뒤 이를 DataFrame으로 변환. 
list2 = [[1, 2, 3],
         [11, 12, 13]]
array2 = np.array(list2)
print('array2 shape:', array2.shape )
df_list2 = pd.DataFrame(list2, columns=col_name2)
print('2차원 리스트로 만든 DataFrame:\n', df_list2)
df_array2 = pd.DataFrame(array2, columns=col_name2)
print('2차원 ndarray로 만든 DataFrame:\n', df_array2)
```

```console
array2 shape: (2, 3)
2차원 리스트로 만든 DataFrame:
    col1  col2  col3
0     1     2     3
1    11    12    13
2차원 ndarray로 만든 DataFrame:
    col1  col2  col3
0     1     2     3
1    11    12    13
```

##### dict -> dataFrame 변환
```python
# Key는 칼럼명으로 매핑, Value는 리스트 형(또는 ndarray)
dict = {'col1':[1, 11], 'col2':[2, 22], 'col3':[3, 33]}
df_dict = pd.DataFrame(dict)
print('딕셔너리로 만든 DataFrame:\n', df_dict)
```

```console
딕셔너리로 만든 DataFrame:
    col1  col2  col3
0     1     2     3
1    11    22    33
```



##### DataFrame을 넘파이 ndarray, 리스트, 딕셔너리로 변환하기

###### DataFrame을 ndarray로 변환
```python
# DataFrame을 ndarray로 변환
array3 = df_dict.values
print('df_dict.values 타입:', type(array3), 'df_dict.values shape:', array3.shape)
print(array3)
```

```console
df_dict.values 타입: <class 'numpy.ndarray'> df_dict.values shape: (2, 3)
[[ 1  2  3]
 [11 22 33]]
```

###### DataFrame을 리스트로 변환
```python
# DataFrame을 리스트로 변환
list3 = df_dict.values.tolist()
print('df_dict.values.tolist() 타입:', type(list3))
print(list3)

# DataFrame을 딕셔너리로 변환
dict3 = df_dict.to_dict('list')
print('\n df_dict.to_dict() 타입:', type(dict3))
print(dict3)
```

```console
df_dict.values.tolist() 타입: <class 'list'>
[[1, 2, 3], [11, 22, 33]]

 df_dict.to_dict() 타입: <class 'dict'>
{'col1': [1, 11], 'col2': [2, 22], 'col3': [3, 33]}
```



#### DataFrame의 칼럼 데이터 세트 생성과 수정
한 방에 새로운 컬럼 생성하고 모든 로우에 값을 할당

```python
titanic_df['Age_0']=0
titanic_df.head(3)
```


기존 컬럼의 값을 이용해서 새로운 컬럼 생성하고 값 입력
```python
titanic_df['Age_by_10'] = titanic_df['Age']*10
titanic_df['Family_No'] = titanic_df['SibSp'] + 
		titanic_df['Parch']+1
titanic_df.head(3)
```

기존 컬럼의 값을 수정하기
```python
titanic_df['Age_by_10'] = titanic_df['Age_by_10'] + 100
titanic_df.head(3)
```


rdb 입장에서는 이렇게 쉽게 하나 싶음.
새로운 컬럼 추가. 
새로운 컬럼 추가하고 값 할당
update문 수행



### DataFrame 데이터 삭제
#### drop()

컬럼, 로우 삭제
axis를 통해서 구분
`axis=0` 은 row 삭제
`axis=1` 은 column 삭제

대부분 DataFrame에서 컬럼 삭제함. 한 90프로?
default가 axis=0이기 때문에 axis=1을 넣는 습관 들여야 한다.


```python
titanic_drop_df = titanic_df.drop('Age_0', axis=1 )
titanic_drop_df.head(3)
```

![[attaches/Pasted image 20250729140451.png]]

원본의 'Age_0' 컬럼은 삭제되지 않았다.


여러 컬럼 삭제하기
list를 넣어서 삭제하면 됨.



`inplace=False`
원본 DataFrame을 그대로 **유지**.
drop된 DataFrame을 새롭게 객체 변수로 받기

메모리를 줄이기 위해 inplace=True 하게 되면
원본을 바꿈. 그리고 반환값 none
그래서 inplace=True일 때는 변수에 할당해봤자 none이다.

titanic_df = titanic_df.drop()


![[attaches/Pasted image 20250729140228.png]]



```python
drop_result = titanic_df.drop(['Age_0', 'Age_by_10', 'Family_No'], axis=1, inplace=True)
print(' inplace=True 로 drop 후 반환된 값:',drop_result)
titanic_df.head(3)
```

![[attaches/Pasted image 20250729140700.png]]

이때 drop_result 변수에 값을 할당하는 것처럼 코드를 작성하게 되면 헷갈린다. 이렇게 쓰지 말 것.
드롭을 자기에 적용했으니까.


##### axis=0 은 row방향 데이터 삭제


```python
pd.set_option('display.width', 1000)
pd.set_option('display.max_colwidth', 15)
print('#### before axis 0 drop ####')
print(titanic_df.head(6))

titanic_df.drop([0,1,2], axis=0, inplace=True)

print('#### after axis 0 drop ####')
print(titanic_df.head(3))
```

```console
#### before axis 0 drop ####
   PassengerId  Survived  Pclass            Name     Sex   Age  SibSp  Parch          Ticket     Fare Cabin Embarked
0            1         0       3  Braund, Mr....    male  22.0      1      0       A/5 21171   7.2500   NaN        S
1            2         1       1  Cumings, Mr...  female  38.0      1      0        PC 17599  71.2833   C85        C
2            3         1       3  Heikkinen, ...  female  26.0      0      0  STON/O2. 31...   7.9250   NaN        S
3            4         1       1  Futrelle, M...  female  35.0      1      0          113803  53.1000  C123        S
4            5         0       3  Allen, Mr. ...    male  35.0      0      0          373450   8.0500   NaN        S
5            6         0       3  Moran, Mr. ...    male   NaN      0      0          330877   8.4583   NaN        Q

#### after axis 0 drop ####
   PassengerId  Survived  Pclass            Name     Sex   Age  SibSp  Parch  Ticket     Fare Cabin Embarked
3            4         1       1  Futrelle, M...  female  35.0      1      0  113803  53.1000  C123        S
4            5         0       3  Allen, Mr. ...    male  35.0      0      0  373450   8.0500   NaN        S
5            6         0       3  Moran, Mr. ...    male   NaN      0      0  330877   8.4583   NaN        Q
```

삭제하고 싶은 row의 index를 [] 안에 넣어서 삭제
삭제 후에 인덱스가 새로 재편되지 않고 기존 인덱스 유지.
인덱스는 고유하기만 하면 되니까 재편할 필요 없음.


### 판다스 Index 객체 이해

인덱스 깊이 이해 못하고 진행하면 나중에 어렵다.

df 는 2차원
series 는 1차원

Index는?
rdbms의 pk와 유사.
레코드를 고유하게 식별하는 객체
but 판다스 Index는 별도 컬럼값 아니다.
Index는 오직 식별용으로만 사용

연산함수는 오직 컬럼에 대해서만 연산한다.
	Index는 연산 함수 적용에서 제외

df.index series.index 속성으로

RangeIndex

판다스 index는 반드시 숫자 아니어도 됨.
고유값을 유지할 수 있다면 문자, Datetime도 가능.

```python
# 원본 파일 재 로딩 
titanic_df = pd.read_csv('titanic_train.csv')
# Index 객체 추출
indexes = titanic_df.index
print(indexes)
# Index 객체를 실제 값 arrray로 변환 
print('Index 객체 array값:\n',indexes.values)

```

```console
RangeIndex(start=0, stop=891, step=1)
Index 객체 array값:
 [  0   1   2  ...... 888 889 890]
```

891에서 stop이니까 891 - 1 까지 값이 들어있다.



```python
print(type(indexes.values)) 
print(indexes.values.shape)
print(indexes[:5].values) # ndarray와 유사하게 동작함.
print(indexes.values[:5]) # 아예 ndarray로 만들어서 print
print(indexes[6])
```

```console
<class 'numpy.ndarray'> 
(891,)
[0 1 2 3 4] 
[0 1 2 3 4]
6
```

인덱스 자체는 wrapping이 ndarray라고 보면 됨.

#### 인덱스는 immutable
값을 할당하는 동작 안 된다.
`indexes[0] = 5` 이런 거 못 해. 
리셋은 가능


인덱스는 오직 식별용. 연산 함수 적용 X

```python
series_fair = titanic_df['Fare']
print(type(series_fair))
print('Fair Series max 값:', series_fair.max())
print('Fair Series sum 값:', series_fair.sum())
print('sum() Fair Series:', sum(series_fair))
print('Fair Series + 3:\n',(series_fair + 3).head(3) )
```

```console
<class 'pandas.core.series.Series'>
Fair Series max 값: 512.3292
Fair Series sum 값: 28693.9493
sum() Fair Series: 28693.9493
Fair Series + 3:
 0    10.2500
1    74.2833
2    10.9250
Name: Fare, dtype: float64
```

DataFrame에 `['colname']`하면 series 리턴
보기에 인덱스 때문에 2차원 처럼 보여도 series다.
값만 연산한다. 1차원임.

#### reset_index()

인덱스를 갈아엎어
새로 할당. 연속 숫자형으로.
기존 인덱스는 'index'라는 새로운 컬럼명으로 추가

```python
titanic_reset_df = titanic_df.reset_index(inplace=False)
titanic_reset_df.head(3)
```

![[attaches/Pasted image 20250729143055.png]]

inplace=False는 호출한 원본 df 유지
새 객체 반환

reset_index() 결과 기존 index는 index 컬럼에 저장.
새 index가 0부터 


```python
titanic_reset_df = titanic_df.reset_index(drop=True, 
		inplace=False)
titanic_reset_df.head(3)
```

drop=True 면 기존 index를 컬럼 추가 안 함.
새 index가 할당 되는 것은 동일함.

reset_index()는 series에 적용할 때 많이 쓴다.


```python
titanic_df['Pclass'].value_counts()
```

```console
Pclass
3    491
1    216
2    184
Name: count, dtype: int64
```

무조건 value_counts()는 값이 큰 순서로 내림차순


```python
print('### before reset_index ###')
value_counts = titanic_df['Pclass'].value_counts()
print(value_counts)
print('value_counts 객체 변수 타입과 shape:',type(value_counts), value_counts.shape)

new_value_counts_01 = value_counts.reset_index(inplace=False)
print('### After reset_index ###')
print(new_value_counts_01)
print('new_value_counts_01 객체 변수 타입과 shape:',type(new_value_counts_01), new_value_counts_01.shape)

new_value_counts_02 = value_counts.reset_index(drop=True, inplace=False)
print('### After reset_index with drop ###')
print(new_value_counts_02)
print('new_value_counts_02 객체 변수 타입과 shape:',type(new_value_counts_02), new_value_counts_02.shape)
```

```console
### before reset_index ###
Pclass
3    491
1    216
2    184
Name: count, dtype: int64
value_counts 객체 변수 타입과 shape: <class 'pandas.core.series.Series'> (3,)
### After reset_index ###
   Pclass  count
0       3    491
1       1    216
2       2    184
new_value_counts_01 객체 변수 타입과 shape: <class 'pandas.core.frame.DataFrame'> (3, 2)
### After reset_index with drop ###
0    491
1    216
2    184
Name: count, dtype: int64
new_value_counts_02 객체 변수 타입과 shape: <class 'pandas.core.series.Series'> (3,)
```



##### reset_index() 주요 사용 예시

```python
# DataFrame의 rename()은 인자로 columns를 dictionary 형태로 받으면 '기존 컬럼명':'신규 컬럼명' 형태로 변환
new_value_counts_01 = titanic_df['Pclass'].value_counts().reset_index()
new_value_counts_01.rename(columns={'index':'Pclass', 'Pclass':'Pclass_count'})
```

![[attaches/Pasted image 20250729144537.png]]


### 판다스 데이터 인덱싱과 필터링

df에 [] 사용
`tdf['Name']`
컬럼기반 필터링
불린 인덱싱 필터링 제공

df와 ndarray 가장 큰 차이
df는 columnName이 있다.


loc[], iloc[]
df가 제공하는 인덱싱 2가지
명칭/위치 기반 인덱싱

모두 **()가 아닌 []** 임에 유의

![[attaches/Pasted image 20250729145117.png]]

[] 안에 단일 컬럼명 -> series 반환

[] 에 여러 컬럼명 list로 입력 -> DataFrame 반환

numpy의 ndarray에서 []는 위치인덱스 값 입력


```python
# DataFrame객체에서 []연산자내에 한개의 컬럼만 입력하면 Series 객체를 반환  
series = titanic_df['Name']
print(series.head(3))
print("## type:",type(series), 'shape:', series.shape)

# DataFrame객체에서 []연산자내에 여러개의 컬럼을 리스트로 입력하면 그 컬럼들로 구성된 DataFrame 반환  
filtered_df = titanic_df[['Name', 'Age']]
display(filtered_df.head(3))
print("## type:", type(filtered_df), 'shape:', filtered_df.shape)

# DataFrame객체에서 []연산자내에 한개의 컬럼을 리스트로 입력하면 한개의 컬럼으로 구성된 DataFrame 반환 
one_col_df = titanic_df[['Name']]
display(one_col_df.head(3))
print("## type:", type(one_col_df), 'shape:', one_col_df.shape)
```

```console
0    Braund, Mr....
1    Cumings, Mr...
2    Heikkinen, ...
Name: Name, dtype: object
## type: <class 'pandas.core.series.Series'> shape: (891,)



## type: <class 'pandas.core.frame.DataFrame'> shape: (891, 2)



## type: <class 'pandas.core.frame.DataFrame'> shape: (891, 1)
```

|     | Name           | Age  |
| --- | -------------- | ---- |
| 0   | Braund, Mr.... | 22.0 |
| 1   | Cumings, Mr... | 38.0 |
| 2   | Heikkinen, ... | 26.0 |

| |Name|
|---|---|
|0|Braund, Mr....|
|1|Cumings, Mr...|
|2|Heikkinen, ...|

내가 한 개의 컬럼이지만 명확하게 DataFrame을 원할 때 이렇게 쓴다.
`df[['columnName']]`



![[attaches/Pasted image 20250729145229.png]]

[] 안에 숫자 사용하면 에러 발생
```python
print('[ ] 안에 숫자 index는 KeyError 오류 발생:\n', titanic_df[0])
```

키 값을 찾아야 해서 안 됨.

반면에 slicing은 가능

```python
titanic_df[0:2]
```

결과 df display()

| PassengerId | Survived | Pclass | Name | Sex            | Age    | SibSp | Parch | Ticket | Fare      | Cabin   | Embarked |     |
| ----------- | -------- | ------ | ---- | -------------- | ------ | ----- | ----- | ------ | --------- | ------- | -------- | --- |
| 0           | 1        | 0      | 3    | Braund, Mr.... | male   | 22.0  | 1     | 0      | A/5 21171 | 7.2500  | NaN      | S   |
| 1           | 2        | 1      | 1    | Cumings, Mr... | female | 38.0  | 1     | 0      | PC 17599  | 71.2833 | C85      | C   |

그러나 [] 안에 slicing을 사용하지마
헷갈린다.
명확하게 iloc[] 연산자를 대신 사용하자.





#### 명칭 기반 인덱싱
명칭(label) 기반 인덱싱. 
컬럼 명칭 기반 열 위치 지정
(행 위치는 index 이용)

위치(Position) 기반 인덱싱은 
0을 출발점으로
가로축, 세로축 좌표 기반 행과 열 위치 기반 데이터 지정
index를 이용하지 않음.

![[attaches/Pasted image 20250729145704.png]]

```python
data = {'Name': ['Chulmin', 'Eunkyung','Jinwoong','Soobeom'],
        'Year': [2011, 2016, 2015, 2015],
        'Gender': ['Male', 'Female', 'Male', 'Male']
       }
data_df = pd.DataFrame(data, index=['one','two','three','four'])
data_df
```

|       | Name     | Year | Gender |
| ----- | -------- | ---- | ------ |
| one   | Chulmin  | 2011 | Male   |
| two   | Eunkyung | 2016 | Female |
| three | Jinwoong | 2015 | Male   |
| four  | Soobeom  | 2015 | Male   |

```python
data_df.iloc[0, 0]
```

```console
'Chulmin'
```

```python
# 아래 코드는 오류를 발생합니다. 
data_df.iloc[0, 'Name']

# 아래 코드는 오류를 발생합니다. 
data_df.iloc['one', 0]
```

```console
Can only index by location with a [integer, integer slice ...
```

iloc는 오직 interager만 가능.




#### 명칭 기반과 위치기반 구분

RangeIndex와 행 위치 개념 동일한 거 아님?
아님
왜?
인덱스는 0부터 시작 x. 문자도 가능. 고유하기만 하면 된다.
어떤 이유에서건 RangeIndex가 변경되었을 때.
`iloc[0, 1]` 값은 변경 X.

`loc[0. 'PassengerID']` 값을 찾을 수 없을 수도

![[attaches/Pasted image 20250729150133.png]]

##### iloc 예제

```python
print("\n iloc[1, 0] 두번째 행의 첫번째 열 값:", data_df.iloc[1,0])
print("\n iloc[2, 1] 세번째 행의 두번째 열 값:", data_df.iloc[2,1])

print("\n iloc[0:2, [0,1]] 첫번째에서 두번째 행의 첫번째, 두번째 열 값:\n", data_df.iloc[0:2, [0,1]])
print("\n iloc[0:2, 0:3] 첫번째에서 두번째 행의 첫번째부터 세번째 열값:\n", data_df.iloc[0:2, 0:3])

print("\n 모든 데이터 [:] \n", data_df.iloc[:])
print("\n 모든 데이터 [:, :] \n", data_df.iloc[:, :])
```

```console
 iloc[1, 0] 두번째 행의 첫번째 열 값: Eunkyung

 iloc[2, 1] 세번째 행의 두번째 열 값: 2015

 iloc[0:2, [0,1]] 첫번째에서 두번째 행의 첫번째, 두번째 열 값:
          Name  Year
one   Chulmin  2011
two  Eunkyung  2016

 iloc[0:2, 0:3] 첫번째에서 두번째 행의 첫번째부터 세번째 열값:
          Name  Year  Gender
one   Chulmin  2011    Male
two  Eunkyung  2016  Female

 모든 데이터 [:] 
            Name  Year  Gender
one     Chulmin  2011    Male
two    Eunkyung  2016  Female
three  Jinwoong  2015    Male
four    Soobeom  2015    Male

 모든 데이터 [:, :] 
            Name  Year  Gender
one     Chulmin  2011    Male
two    Eunkyung  2016  Female
three  Jinwoong  2015    Male
four    Soobeom  2015    Male
```



보통 데이터프레임에서 iloc를 언제 많이 쓰는지
맨 마지막 데이터가 타겟일 경우.


```python
print("\n 맨 마지막 칼럼 데이터 [:, -1] \n", data_df.iloc[:, -1])
print("\n 맨 마지막 칼럼을 제외한 모든 데이터 [:, :-1] \n", data_df.iloc[:, :-1])
```

```console
맨 마지막 칼럼 데이터 [:, -1] 
 one        Male
two      Female
three      Male
four       Male
Name: Gender, dtype: object

 맨 마지막 칼럼을 제외한 모든 데이터 [:, :-1] 
            Name  Year
one     Chulmin  2011
two    Eunkyung  2016
three  Jinwoong  2015
four    Soobeom  2015
```



iloc는 불린 인덱싱 지원 X


##### loc 예제

```python
data_df.loc['one', 'Name']
```

```console
'Chulmin'
```


인덱스가 'one' 이라 0을 넣으면 에러

인덱스가 문자일 때 slicing 하면 endIndex 포함 여부

```python
print('위치기반 iloc slicing\n', data_df.iloc[0:1, 0],'\n')
print('명칭기반 loc slicing\n', data_df.loc['one':'two', 'Name'])
```

```console
위치기반 iloc slicing
 one    Chulmin
Name: Name, dtype: object 

명칭기반 loc slicing
 one     Chulmin
two    Eunkyung
Name: Name, dtype: object
```

문자열 'two'에서 -1을 할 수 없기 때문에 'two' 행이 결과에 포함시켜 반환.
slicing 할 때 주의.
이러한 함정들이 있어서 잘 안 쓰고 불린 인덱싱을 주로 사용한다.


```python
print('인덱스 값 three인 행의 Name칼럼값:', data_df.loc['three', 'Name'])
print('\n인덱스 값 one 부터 two까지 행의 Name과 Year 칼럼값:\n', data_df.loc['one':'two', ['Name', 'Year']])
print('\n인덱스 값 one 부터 three까지 행의 Name부터 Gender까지의 칼럼값:\n', data_df.loc['one':'three', 'Name':'Gender'])
print('\n모든 데이터 값:\n', data_df.loc[:])
print('\n불린 인덱싱:\n', data_df.loc[data_df.Year >= 2014])
```

```console
인덱스 값 three인 행의 Name칼럼값: Jinwoong

인덱스 값 one 부터 two까지 행의 Name과 Year 칼럼값:
          Name  Year
one   Chulmin  2011
two  Eunkyung  2016

인덱스 값 one 부터 three까지 행의 Name부터 Gender까지의 칼럼값:
            Name  Year  Gender
one     Chulmin  2011    Male
two    Eunkyung  2016  Female
three  Jinwoong  2015    Male

모든 데이터 값:
            Name  Year  Gender
one     Chulmin  2011    Male
two    Eunkyung  2016  Female
three  Jinwoong  2015    Male
four    Soobeom  2015    Male

불린 인덱싱:
            Name  Year  Gender
two    Eunkyung  2016  Female
three  Jinwoong  2015    Male
four    Soobeom  2015    Male
```

**loc는 불린 인덱싱 can**


#### 불린 인덱싱

위치기반, 명칭 기반 필요 없음.
조건식을 [] 안에 기입
간편한 필터링 can

조건에 해당되는 데이터를 출력할 일이 훨씬 많다.

`tdf_boolean = tdf[tdf['Age'] > 60]`


반면에 위치 기반 사용 예시
`tdf[:, :-1]` 
맨 마지막 컬럼의 값, 모든 row를 다 가져오기


```python
titanic_df[ titanic_df['Pclass'] == 3].head(3)
```

|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|
|---|---|---|---|---|---|---|---|---|---|---|---|
|0|1|0|3|Braund, Mr....|male|22.0|1|0|A/5 21171|7.250|NaN|S|
|2|3|1|3|Heikkinen, ...|female|26.0|0|0|STON/O2. 31...|7.925|NaN|S|
|4|5|0|3|Allen, Mr. ...|male|35.0|0|0|373450|8.050|NaN|S|

Pclass가 3인 행 3개 가져와라.


```python
pd.set_option('display.max_colwidth', 200)
titanic_df = pd.read_csv('titanic_train.csv')
titanic_boolean = titanic_df[titanic_df['Age'] > 60]
print(type(titanic_boolean))
```

```console
<class 'pandas.core.frame.DataFrame'>
```



```python
titanic_df[titanic_df['Age'] > 60][['Name','Age']].head(3)
```

|     | Name                           | Age  |
| --- | ------------------------------ | ---- |
| 33  | Wheadon, Mr. Edward H          | 66.0 |
| 54  | Ostby, Mr. Engelhart Cornelius | 65.0 |
| 96  | Goldschmidt, Mr. George B      | 71.0 |

앞에는 불린 인덱싱, 뒤에 컬럼은 2개 이상이므로 [] 안에 리스트로 넣음

동일한 불린 인덱싱을 loc를 써서도 수행 can

```python
titanic_df.loc[titanic_df['Age'] > 60, ['Name','Age']].head(3)
```

but 둘다 쓰려면 혼동

& 조건식

```python
titanic_df[ (titanic_df['Age'] > 60) & (titanic_df['Pclass']==1) & (titanic_df['Sex']=='female')]
```

|     | PassengerId | Survived | Pclass | Name                                      | Sex    | Age  | SibSp | Parch | Ticket | Fare    | Cabin | Embarked |
| --- | ----------- | -------- | ------ | ----------------------------------------- | ------ | ---- | ----- | ----- | ------ | ------- | ----- | -------- |
| 275 | 276         | 1        | 1      | Andrews, Miss. Kornelia Theodosia         | female | 63.0 | 1     | 0     | 13502  | 77.9583 | D7    | S        |
| 829 | 830         | 1        | 1      | Stone, Mrs. George Nelson (Martha Evelyn) | female | 62.0 | 0     | 0     | 113572 | 80.0000 | B28   | NaN      |

**개별 조건을 반드시 () 로 감싸**


```python
cond1 = titanic_df['Age'] > 60
cond2 = titanic_df['Pclass']==1
cond3 = titanic_df['Sex']=='female'
titanic_df[ cond1 & cond2 & cond3]
```

조건식이 복잡할 때 가독성을 높이기 위해 별도 변수에 할당하는 방법
결과는 같음.


